import logging
import asyncio
from pydantic import Field
from typing import Annotated
from dotenv import load_dotenv


from livekit import agents, rtc
from livekit.agents import (
    AgentServer,
    AgentSession,
    Agent,
    inference,
    room_io,
    RunContext,
    function_tool,
)
from livekit.plugins import noise_cancellation, silero
from livekit.plugins.turn_detector.multilingual import MultilingualModel

load_dotenv(".env.local")

logger = logging.getLogger(__name__)


class Assistant(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=(
                "You are a helpful, friendly voice AI assistant with a warm and engaging personality. "
                "You assist users with their questions and requests using your extensive knowledge. "
                "Keep your responses concise, natural, and conversational. "
                "Avoid complex formatting, emojis, or special punctuation. "
                "Your first message should always be: 'Hello! How can I help you today?' "
                "If the user asks to end the call or says goodbye, call the end_conversation tool. "
                "Do not say goodbye yourself â€” the tool will speak and end the call."
            ),
        ),

    @function_tool
    async def end_conversation(
        self,
        context: RunContext,
        reason: Annotated[str, Field(description="Why the call is ending")],
    ) -> None:
        logger.info(f"End requested: {reason}")

        await context.session.say(
            "Alright, thanks for chatting with me. Take care and have a great day!",
            allow_interruptions=False,
        )

        context.session.shutdown(drain=True)


server = AgentServer()


@server.rtc_session()
async def entrypoint(ctx: agents.JobContext):
    session = AgentSession(
        stt=inference.STT(
            model="cartesia/ink-whisper",
            language="en",
        ),
        llm=inference.LLM(
            model="openai/gpt-5-mini",
        ),
        tts=inference.TTS(
            model="inworld/inworld-tts-1.5-max",
            voice="Craig",
            language="en",
        ),
        vad=silero.VAD.load(),
        turn_detection=MultilingualModel(),
    )

    @session.on("conversation_item_added")
    def on_conversation_item_added(ev):
        if hasattr(ev, "item"):
            logger.info(f"[Chat] {ev.item.role}: {ev.item.content}")

    await session.start(
        room=ctx.room,
        agent=Assistant(),
        room_options=room_io.RoomOptions(
            delete_room_on_close=True,
            audio_input=room_io.AudioInputOptions(
                noise_cancellation=lambda params: (
                    noise_cancellation.BVCTelephony()
                    if params.participant.kind
                    == rtc.ParticipantKind.PARTICIPANT_KIND_SIP
                    else noise_cancellation.BVC()
                ),
            ),
        ),
    )

    await session.generate_reply(
        instructions="Hello! How can I help you today?",
        allow_interruptions=True,
    )


if __name__ == "__main__":
    agents.cli.run_app(server)
