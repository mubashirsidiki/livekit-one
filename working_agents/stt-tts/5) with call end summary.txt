import logging
from pydantic import Field
from typing import Annotated
from dotenv import load_dotenv


from livekit import agents, rtc
from livekit.agents import (
    AgentServer,
    AgentSession,
    Agent,
    ChatContext,
    inference,
    room_io,
    RunContext,
    function_tool,
)
from livekit.plugins import noise_cancellation, silero
from livekit.plugins.turn_detector.multilingual import MultilingualModel

load_dotenv(".env.local")

logger = logging.getLogger(__name__)


class Assistant(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=(
                "You are a helpful, friendly voice AI assistant with a warm and engaging personality. "
                "You assist users with their questions and requests using your extensive knowledge. "
                "Keep your responses concise, natural, and conversational. "
                "Avoid complex formatting, emojis, or special punctuation. "
                "Your first message should always be: 'Hello! How can I help you today?' "
                "If the user asks to end the call or says goodbye, call the end_conversation tool. "
                "Do not say goodbye yourself â€” the tool will speak and end the call."
            ),
        ),

    @function_tool
    async def end_conversation(
        self,
        context: RunContext,
        reason: Annotated[str, Field(description="Why the call is ending")],
    ) -> None:
        logger.info(f"End requested: {reason}")

        await context.session.say(
            "Alright, thanks for chatting with me. Take care and have a great day!",
            allow_interruptions=False,
        )

        context.session.shutdown(drain=True)


server = AgentServer()


async def _summarize_session(
    summarizer: inference.LLM, chat_ctx: ChatContext
) -> str | None:
    """Generate a summary of the conversation."""
    summary_ctx = ChatContext()
    summary_ctx.add_message(
        role="system",
        content=(
            "Summarize the following conversation between a user and an AI assistant. "
            "Provide a concise summary highlighting the main points discussed and the "
            "outcome of the interaction and evaluate the conversation in terms of perceived "
            "helpfulness (user sentiment), clarity, and engagement. "
            "Format the summary as follows:\n\n"
            "# Summary:\n"
            "<bullet-pointed summary of key events and interactions, outcome>\n\n"
            "# Evaluation:\n"
            "- Helpfulness: <assesment of perceived helpfulness and user sentiment>\n"
            "- Clarity: <assesment of clarity of responses>\n"
            "- Engagement: <assesment of engagement level>\n"
        ),
    )

    n_summarized = 0
    for item in chat_ctx.items:
        if item.type != "message":
            continue
        if item.role not in ("user", "assistant"):
            continue
        if item.extra.get("is_summary") is True:  # avoid making summary of summaries
            continue

        text = (item.text_content or "").strip()
        if text:
            summary_ctx.add_message(
                role="user",
                content=f"{item.role}: {(item.text_content or '').strip()}",
            )
            n_summarized += 1

    if n_summarized == 0:
        logger.debug("No chat messages to summarize")
        return None

    chunks: list[str] = []
    async for chunk in summarizer.chat(chat_ctx=summary_ctx):
        if chunk.delta and chunk.delta.content:
            chunks.append(chunk.delta.content)

    return "".join(chunks).strip()


async def _on_session_end(ctx: agents.JobContext) -> None:
    """Handle session end by generating and logging a summary."""
    # Get the chat history from the session report
    report = ctx.make_session_report()

    # Create summarizer with LLM
    summarizer = inference.LLM(model="openai/gpt-5-mini")

    # Generate summary
    summary = await _summarize_session(summarizer, report.chat_history)

    if summary:
        logger.info(f"\n{'='*60}\nSESSION SUMMARY:\n{summary}\n{'='*60}")
    else:
        logger.info("No summary generated for session")


@server.rtc_session(on_session_end=_on_session_end)
async def entrypoint(ctx: agents.JobContext):
    session = AgentSession(
        stt=inference.STT(
            model="cartesia/ink-whisper",
            language="en",
        ),
        llm=inference.LLM(
            model="openai/gpt-5-mini",
        ),
        tts=inference.TTS(
            model="inworld/inworld-tts-1.5-max",
            voice="Craig",
            language="en",
        ),
        vad=silero.VAD.load(),
        turn_detection=MultilingualModel(),
    )

    @session.on("conversation_item_added")
    def on_conversation_item_added(ev):
        if hasattr(ev, "item"):
            logger.info(f"[Chat] {ev.item.role}: {ev.item.content}")

    await session.start(
        room=ctx.room,
        agent=Assistant(),
        room_options=room_io.RoomOptions(
            delete_room_on_close=True,
            audio_input=room_io.AudioInputOptions(
                noise_cancellation=lambda params: (
                    noise_cancellation.BVCTelephony()
                    if params.participant.kind
                    == rtc.ParticipantKind.PARTICIPANT_KIND_SIP
                    else noise_cancellation.BVC()
                ),
            ),
        ),
    )

    await session.generate_reply(
        instructions="Hello! How can I help you today?",
        allow_interruptions=True,
    )


if __name__ == "__main__":
    agents.cli.run_app(server)
